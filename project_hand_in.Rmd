---
title: "Final Project For Statistical Learning II"
author: "Ivan Padezhki"
date: "April 20, 2022"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax
for authoring HTML, PDF, and MS Word documents. For more details on
using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that
includes both content as well as the output of any embedded R code
chunks within the document. You can embed an R code chunk like this:

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to
prevent printing of the R code that generated the plot.

# Libraries

```{r, echo=FALSE}
library(tidyverse)
library(corrplot)
library(Hmisc)
library(corrplot)
library(RColorBrewer)
```

# 1. Input of data

## 1.1. Dataset Breast Cancer

<https://www.kaggle.com/code/leemun1/predicting-breast-cancer-logistic-regression/data>,
first accessed 30/05/2022

```{r}
ds <- read.csv("data/diabetes_dataset__2019.csv")
names(ds)
attach(ds)
```

```{r}
ds[1:5,]
```

```{r}
summary(ds)
# X is a logical variable that contains only missing values - remove it
```

# 2. Overall cleaning

## 2.1. Identifying Missing Values

Check for any missing values after removing the X column

```{r}
sum(is.na(ds)==TRUE)
```

# 3. Data Exploration

figure out what relevant questions there are in the data Inspect data
and its features what data types are there (numerical, categorical,
ordinal) - they require different treatments

## 3.1. Descriptive statistics

visualizations: identify patterns and trends in the data organize and
tidy the data

```{r}
hist(ds)
```

```{r}
# check correlation between variables
df_cor <- ds %>% mutate_if(is.character, as.factor)
df_cor <- df_cor %>% mutate_if(is.factor, as.numeric)
#run a correlation and drop the insignificant ones
corr <- cor(df_cor)
#prepare to drop duplicates    
corr[lower.tri(corr,diag=TRUE)] <- NA 
# print the corr matrix
# print(corr)
```

plot the corr matrix

```{r}
#plot correlations visually
corrplot(corr, is.corr=FALSE, tl.col="black", na.label=" ")
```

```{r}
corrplot(cor(df_cor), type="upper", order="hclust",
         col=brewer.pal(n=8, name="RdYlBu"))
```

From the correlation plot, we can see that certain variables are highly
correlated. Let's check which ones have a correlation above .90
(arbitrarily chosen so we can see multicollinearity) AND we select only
the upper triangle

```{r}
w <- which(corr>0.9 & row(corr)<col(corr), arr.ind = TRUE)
# reconstruct names from positions
high_cor <- matrix(colnames(corr)[w],ncol=2)
high_cor
```

Check type of the variable that we want to predict and turn it onto
factor with two levels

```{r}
class(diagnosis)
# turn it into factor
ds$diagnosis <- as.factor(ds$diagnosis)
# check the levels: should be B for benign and M for malignant
levels(ds$diagnosis)
```

Plot distribution of the classes

```{r}
plot(ds$diagnosis)
```

End up with a data in a standardized format across all data

Potentially concentrate on a subset of the data: the set contains mean
and standard dev of 10 main characteristics

# 4. Model data

Use regression and predictions for forecasting future values Or use
classification to identify groups

Reduce dimensionality of the data set - not all our values are
essentials to predicting the model

Select relevant features that contribute to the prediction of results or
apply shrinkage regressions

# 5. Interpret data

How do we present our analysis: basically answer the questions we set in
the beginning using our results - technical details are necessary but
make them accessible - tell a story
